--- /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py
+++ /usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py
@@ -23,7 +23,7 @@
           dimensions
         - Output: :math:`(N, *)`, same shape as the input
 
-    .. image:: ../scripts/activation_images/LeakyReLU.png
+    .. image:: scripts/activation_images/LeakyReLU.png
 
     Examples::
 
@@ -32,18 +32,16 @@
         >>> output = m(input)
     """
     __constants__ = ['inplace', 'negative_slope']
-    inplace: bool
-    negative_slope: float
 
-    def __init__(self, negative_slope: float = 1e-2, inplace: bool = False) -> None:
+    def __init__(self, negative_slope=1e-2, inplace=False):
         super(LeakyReLU, self).__init__()
         self.negative_slope = negative_slope
         self.inplace = inplace
 
-    def forward(self, input: Tensor) -> Tensor:
+    def forward(self, input):
         return F.leaky_relu(input, self.negative_slope, self.inplace)
 
-    def extra_repr(self) -> str:
+    def extra_repr(self):
         inplace_str = ', inplace=True' if self.inplace else ''
         return 'negative_slope={}{}'.format(self.negative_slope, inplace_str)
 